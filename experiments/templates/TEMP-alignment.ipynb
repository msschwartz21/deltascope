{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook facilitates the manual curation of sample alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deltascope.alignment as ut\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable interactive matplotlib plots to allow us to update plots as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use the `inline` magic for static plots that flexibly resize to fit the current window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# -------- User input ------------\n",
    "# --------------------------------\n",
    "\n",
    "param = {\n",
    "    'gthresh':0.5,\n",
    "    'scale':[1,1,1],\n",
    "    'microns':[0.16,0.16,0.21],\n",
    "    'mthresh':0.5,\n",
    "    'radius':10,\n",
    "    'comp_order':[0,2,1],\n",
    "    'fit_dim':['x','z'],\n",
    "    'deg':2,\n",
    "    \n",
    "    # Don't forget to modify this with a specific sample name\n",
    "    'expname':'expname'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# -------- User input ------------\n",
    "# --------------------------------\n",
    "\n",
    "# Specify file paths to directories containing probability files\n",
    "# after processing by ilastik\n",
    "gfap = os.path.abspath('..\\expname\\GFAP\\Prob')\n",
    "at = os.path.abspath('..\\expname\\AT\\Prob')\n",
    "\n",
    "# Specify root directory where output will be saved\n",
    "root = os.path.abspath('..\\expname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory with timestamp\n",
    "outname = 'Output_'+time.strftime(\"%m-%d-%H-%M\",\n",
    "                                 time.localtime())\n",
    "\n",
    "# Create output directory\n",
    "outdir = os.path.join(root,outname)\n",
    "os.mkdir(outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dat = {}\n",
    "for f in os.listdir(at):\n",
    "    if 'h5' in f:\n",
    "        num  = re.findall(r'\\d+',f.split('.')[0])[-1]\n",
    "        Dat[num] = os.path.join(at,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dzrf = {}\n",
    "for f in os.listdir(gfap):\n",
    "    if 'h5' in f:\n",
    "        num  = re.findall(r'\\d+',f.split('.')[0])[-1]\n",
    "        Dzrf[num] = os.path.join(gfap,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract list of filename keys\n",
    "klist = Dat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries to contain the deltascope brain object for each sample\n",
    "Dbat = {}\n",
    "Dbzrf = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raw data and perform preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zfishlab\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:110: UserWarning: Possible precision loss when converting from float32 to uint8\n",
      "  \"%s to %s\" % (dtypeobj_in, dtypeobj))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "11\n",
      "010\n",
      "09\n",
      "016\n",
      "02\n",
      "14\n",
      "10\n",
      "014\n",
      "5\n",
      "07\n",
      "12\n",
      "03\n",
      "16\n",
      "08\n",
      "13\n",
      "2\n",
      "7\n",
      "012\n",
      "06\n",
      "Wall time: 12min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for k in tqdm.tqdm(klist):\n",
    "    if k not in list(Dbat.keys()):\n",
    "        Dbat[k] = ut.preprocess(Dat[k],param)\n",
    "        Dbzrf[k] = ut.preprocess(Dzrf[k],param,pca=Dbat[k].pcamed,\n",
    "                                 mm=Dbat[k].mm,vertex=Dbat[k].vertex)\n",
    "    else:\n",
    "        print(k,'already processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define experiment specific functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Define wrapper functions for starting and saving to minimize the number \n",
    "of inputs that the user needs to type for each call of the function.'''\n",
    "def start(k):\n",
    "    return(ut.start(k,Dbat,[Dbzrf],im=True))\n",
    "def save_both(k,dfa,dfb):\n",
    "    ut.save_both(k,dfa,dfb,outdir,param.expname)\n",
    "\n",
    "'''Save model parameters for each file to a dataframe that can be \n",
    "exported for later reference.'''\n",
    "model = pd.DataFrame({'a':[],'b':[],'c':[]})\n",
    "def save_model(k,mm,model):\n",
    "    row = pd.Series({'a':mm[0],'b':mm[1],'c':mm[2]},name=k)\n",
    "    model = model.append(row)\n",
    "    return(model)\n",
    "\n",
    "'''Define a function that can both fit a model and plot it on an existing plot'''\n",
    "def fit_model(axi,df,mm=None):\n",
    "    if mm == None:\n",
    "        mm = np.polyfit(df.x,df.z,2)\n",
    "    p = np.poly1d(mm)\n",
    "    xrange = np.arange(np.min(df.x),np.max(df.x))\n",
    "    axi.plot(xrange,p(xrange),c='m')\n",
    "    return(mm)\n",
    "\n",
    "'''Take a set of points and transform to a dataframe format for ease of access.'''\n",
    "def pick_pts(x1,z1,vx,vz,x2,z2):\n",
    "    pts = pd.DataFrame({'x':[x1,vx,x2],'z':[z1,vz,z2]})\n",
    "    return(pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example alignment\n",
    "\n",
    "The `start` function initializes a sample for alignment. It displays a plot of the data with three projections (XY, XZ, and ZY) that should give a general sense of sample alignment. Note, that the `start` function attempts to align the sample using PCA. In some really bad cases, it is better to work on a sample without PCA alignment, in which case we can use the following code to initialize:\n",
    "```python\n",
    "k = klist[0]\n",
    "df,Ldf = get_dfs(k)\n",
    "ax = ut.make_graph([df]+Ldf)\n",
    "```\n",
    "\n",
    "In most cases, the following approach will be appropriate.\n",
    "\n",
    "```python\n",
    "k,df,Ldf,ax = start(klist[0])\n",
    "```\n",
    "\n",
    "`k`: The dictionary key that identifies this sample. It should be the sample number extracted from the filename.  \n",
    "`df`: The dataframe containing datapoints associated with the primary alignment channel, in this case, AT.  \n",
    "`Ldf`: A list of additional dataframes corresponding to other channels in the collection. In this template, we are assuming only one additional channel, ZRF.  \n",
    "`ax`: The array containing subplots for this sample. There should be three projections for each channel and a row per channel. In this example the dimensions of the array are 2x3.\n",
    "\n",
    "## Correction options\n",
    "\n",
    "![alignment-correction](alignment-correction.jpg)\n",
    "\n",
    "### A: Rotation around the X axis\n",
    "This rotation error can best be identified in the YZ projection where the line of the sample does not fall on either axis. In order to correct this error, we will select two points in YZ that will be used to calculate a line that fits the sample. We can then use this line to calculate the angle of rotation needed to align the sample with the Z axis.\n",
    "\n",
    "To perform this rotation, we will use the `ut.check_yz` function, which will fit a line in the YZ plane to use for rotation. This function takes only `df` and `Ldf` as required inputs.\n",
    "\n",
    "```python\n",
    "df1,Ldf1,ax,p = ut.check_yz(df,Ldf)\n",
    "```\n",
    "\n",
    "This function returns updated verions of `df` and `Ldf` following the rotation. I typically define new variables `df1` and `Ldf1` to keep track of the changes. It also returns a plotting object `ax` that will display a before and after comparison of the alignment with the points used for alignment plotted on the before plot for reference. Finally, it returns the `np.poly1d` object which contains the line that was used for alignment.\n",
    "\n",
    "If the results of this alignment are good, we can proceed with `df1` and `Ldf1`. Alternatively, we can try to manually assign an improved line and pass the resulting `np.poly1d` object to `ut.check_yz` as an optional arguement `ut.check_yz(df,Ldf,mm=np.poly1d)`.\n",
    "\n",
    "### B: Rotation around the Y axis\n",
    "This error can be seen in the XZ projection where the parabola of the sample is tilted towards one side or the other. In order to correct this error, we will select two points that mark the endpoints of the parabola. The line between these two points will be used to calculate the angle of rotation to correct the parabola.  \n",
    "\n",
    "To perform this rotation, we will use the `check_pts` function, which will perform a rotation either in the XY or XZ plane. It requires three parameters: `df`, `Ldf`, and the second dimension of the plane of interest (`'y'` or `'z'`).\n",
    "\n",
    "```python\n",
    "# Attempt rotation based on alignment points calculated from the data\n",
    "df1,Ldf1,pts,ax = ut.check_pts(df,Ldf,'z')\n",
    "```\n",
    "\n",
    "In addition to typical outputs, this function returns `pts`, which is a pandas dataframe specifying two points in the XZ plane that were used for alignment.\n",
    "\n",
    "If we are unhappy with the results of the alignment, we can manually adjust the anchor points and then recalculate the rotation.\n",
    "\n",
    "```python\n",
    "# Assign new values to pts\n",
    "pts.iloc[0].x = 10\n",
    "pts.iloc[1].z = 50\n",
    "\n",
    "# Replot the updated pts to check choices\n",
    "ax[0,1].scatter(pts.x,pts.z,c='y')\n",
    "```\n",
    "\n",
    "If these `pts` look good, then we can use `ut.revise_pts` to recalculate the rotation.\n",
    "\n",
    "```python\n",
    "df2,Ldf2,ax = ut.revise_pts(df,Ldf,'z',pts=pts)\n",
    "```\n",
    "\n",
    "If we are happy with these results, we could use `df2` and `Ldf2` to save as our final result.\n",
    "\n",
    "### C: Mismatched Y and Z axes\n",
    "Here the parabola appears in the XY projection when we expect it in the XZ projection. We can correct this by simply switching the Y and Z axes. The `ut.zyswitch` function facilitates this process.\n",
    "\n",
    "```python\n",
    "df1,Ldf1 = zyswitch(df,Ldf)\n",
    "# Plot data to check correction result\n",
    "ax = ut.make_graph(df1,Ldf1)\n",
    "```\n",
    "\n",
    "### D: Upside down parabola\n",
    "We expect the parabola to lie in the positive half of the Z dimension. To correct an upside down parabola, we rotate the sample by 180$^\\circ$ around X axis. Here, we will use the `ut.flip` function.\n",
    "\n",
    "```python\n",
    "df1,Ldf1 = ut.flip(df,Ldf)\n",
    "# Plot data to check correction result\n",
    "ax = ut.make_graph(df1,Ldf1)\n",
    "```\n",
    "\n",
    "## Correct vertex \n",
    "After performing the corrections described in the previous section, the vertex of the parabola may no longer be positioned at the origin. The function `ut.ch_vertex` attempts to reposition the vertex to the origin. This function also returns the math model `mm`, which describes the parabola of the data. We will save `mm` for future reference.\n",
    "\n",
    "For this example, we will assume that we are happy with the alignment in `df1` and `Ldf1`.\n",
    "\n",
    "```python\n",
    "df2,Ldf2,mm,ax = ut.ch_vertex(df1,Ldf1)\n",
    "```\n",
    "\n",
    "If we disagree with the assignment of the vertex, we can manually pick three points that will be used to recalculate the vertex. These points should mark the two ends of the parabola (x1,z1) and (x2,z2) as well as the approximate vertex (vx,vz). We can specify and check these points before using them to shift the sample.\n",
    "\n",
    "```python\n",
    "pts = pick_pts(-78,12,-36,0,0,10) #these are essentially random numbers for example\n",
    "ax[0,1].scatter(pts.x,pts.z,c='m',s=50)\n",
    "```\n",
    "\n",
    "Finally if we like these points, we can run `ut.ch_vertex` again with these specific points.\n",
    "\n",
    "```python\n",
    "df3,Ldf3,mm,ax = ut.ch_vertex(df2,Ldf2,pts=pts)\n",
    "```\n",
    "\n",
    "In order to complete the alignment process, we need to add the math model `mm` to dataframe for future reference and save the aligned data.\n",
    "\n",
    "```python\n",
    "model = save_model(k,mm,model)\n",
    "save_both(k,df3,Ldf3[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process remaining samples\n",
    "The workflow presented in the section above needs to be applied to all samples in `klist`. It is up to the user to decide which corrections are appropriate for each individual sample. I recommend that this review is also used as an opportunity to exclude samples with issues in the raw data, such as tears in the commissure or limited signal. The reason for rejecting a sample can be recorded in this notebook for future reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping up: after all samples are processed\n",
    "Once all of the data has been processed, we want to save the model data we collected to a file for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to_csv(os.path.join(outdir,'model.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, it can be helpful to export a html or pdf version of the notebook that preserves all of the plots generated during the alignment process. To do so, use the Jupyter Lab menu interface: File > Export Notebook As > HTML or PDF."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deltascope]",
   "language": "python",
   "name": "conda-env-deltascope-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
